{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BlancoAnna/NLP-Notebooks/blob/main/l5_prob_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXYMGLM2UTG1"
      },
      "source": [
        "# Sequence Labeling - NER\n",
        "\n",
        "*Based on work by Adri Molina.*\n",
        "\n",
        "The extraction of relevant information from historical handwritten document collections\n",
        "is one of the key steps in order to make these manuscripts available for access and\n",
        "searches. In this context, instead of a pure transcription, the objective is to move\n",
        "towards document understanding. Concretely, the aim is to detect the named entities and\n",
        "assign each of them a semantic category, such as family names, places, occupations, etc.\n",
        "\n",
        "A typical application scenario of named entity recognition are demographic documents,\n",
        "since they contain people's names, birthplaces, occupations, etc. In this scenario, the\n",
        "extraction of the key contents and its storage in databases allows the access to their\n",
        "contents and envision innovative services based in genealogical, social or demographic\n",
        "searches.\n",
        "\n",
        "<p style = 'text-align: center'>\n",
        "<img src = \"http://dag.cvc.uab.es/wp-content/uploads/2016/07/esposalla_detall.jpg\">\n",
        "</p>\n",
        "\n",
        "Usage of Google Colab is not mandatory, but highly recommended as most of the behaviors\n",
        "are expected for a Linux VM with IPython bindings.\n",
        "\n",
        "## First, we will install the unmet dependencies.\n",
        "\n",
        "This will download some packages and the required data, it may take a while."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R8Rcfr3oUAms"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "from IPython.display import clear_output\n",
        "\n",
        "!git clone https://github.com/EauDeData/nlp-resources\n",
        "!cp -r nlp-resources/ resources/\n",
        "!rm -rf nlp-resources/\n",
        "\n",
        "%pip install nltk\n",
        "%pip install scikit-learn\n",
        "%pip install git+https://github.com/MeMartijn/updated-sklearn-crfsuite\n",
        "clear_output()\n",
        "\n",
        "from typing import *\n",
        "\n",
        "import nltk\n",
        "import numpy as np\n",
        "import copy\n",
        "import random\n",
        "from collections import Counter\n",
        "\n",
        "import pycrfsuite as crfs\n",
        "from sklearn_crfsuite import scorers\n",
        "from sklearn_crfsuite import metrics\n",
        "\n",
        "from resources.data.dataloaders import EsposallesTextDataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LbPYoxkYGUa"
      },
      "source": [
        "## Data Processing\n",
        "Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NRLKbU-4UQ8O"
      },
      "outputs": [],
      "source": [
        "random.seed(42)\n",
        "train_loader = EsposallesTextDataset('resources/data/esposalles/')\n",
        "test_loader = copy.deepcopy(train_loader)\n",
        "test_loader.test()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzOLIKMGUGAD"
      },
      "source": [
        "Example of data from each loader:\n",
        "> Format string: ```word```:```label```\n",
        "\n",
        "This is a simple IO tagging format which, for the task at hand, should be more than\n",
        "enough\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6nElJ2-ZCJe",
        "outputId": "3a2b6d41-dd67-4c28-a19a-241410bbd03e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Dilluns:other', 'a:other', '5:other', 'rebere:other', 'de:other', 'Hyacinto:name', 'Boneu:surname', 'hortola:occupation', 'de:other', 'Bara:location', 'fill:other', 'de:other', 'Juan:name', 'Boneu:surname', 'parayre:occupation', 'defunct:other', 'y:other', 'de:other', 'Maria:name', 'ab:other', 'Anna:name', 'donsella:state', 'filla:other', 'de:other', 't:name', 'Cases:surname', 'pages:occupation', 'de:other', 'Bara:location', 'defunct:other', 'y:other', 'de:other', 'Peyrona:name']\n",
            "['Divendres:other', 'a:other', '18:other', 'rebere:other', 'de:other', 'Juan:name', 'Torres:surname', 'pages:occupation', 'habitant:other', 'en:other', 'Sabadell:location', 'fill:other', 'de:other', 'Bernat:name', 'Torres:surname', 'pages:occupation', 'de:other', 'Moya:location', 'bisbat:location', 'de:location', 'Vich:location', 'y:other', 'de:other', 'Antiga:name', 'defucts:other', 'ab:other', 'Margarida:name', 'donsella:state', 'filla:other', 'de:other', 'Juan:name', 'Argemir:surname', 'pages:occupation', 'de:other', 'Sabadell:location', 'y:other', 'de:other', 'Aldonsa:name', 'defuncts:other']\n"
          ]
        }
      ],
      "source": [
        "print([f\"{x}:{y}\" for x,y in zip(*train_loader[0])])\n",
        "print([f\"{x}:{y}\" for x,y in zip(*test_loader[0])])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXOg5M3-lg5J"
      },
      "source": [
        "If the dataset is correctly downloaded you will see two different samples above, and both tests passed below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7_mFDqOkcnW",
        "outputId": "d78ca015-8666-4c58-c8eb-24467f503ce6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "train_set test passed\n",
            "test_set test passed\n"
          ]
        }
      ],
      "source": [
        "# Check Dataset\n",
        "\n",
        "for idx in range(len(train_loader)):\n",
        "\n",
        "    x, y = train_loader[idx]\n",
        "    if len(x) != len(y):\n",
        "        print(\"train_set test not passed\")\n",
        "        break\n",
        "    else:\n",
        "        print(\"train_set test passed\")\n",
        "\n",
        "for idx in range(len(test_loader)):\n",
        "\n",
        "    x, y = test_loader[idx]\n",
        "    if len(x) != len(y):\n",
        "        print(\"test_set test not passed\")\n",
        "        break\n",
        "\n",
        "else:\n",
        "    print(\"test_set test passed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqp5OuN8YTwj"
      },
      "source": [
        "## An example of a typical pre-processing pipeline\n",
        "\n",
        "Let's do a quick exercise to get acquainted with the data.\n",
        "\n",
        "Most efficient implementations of these kinds of algorithms do not use words encoded as\n",
        "strings directly. Usually, one would first convert each word into an integer index that\n",
        "is stored succintly and contiguously in memory and perform all computations with it.\n",
        "The way this is usually done is through a Look Up Table (LUT), which can be implemented\n",
        "very easily in Python using a map (Dictionary).\n",
        "\n",
        "Furthermore, many packages will process multiple sentences at once. However, the fact\n",
        "that there are variable length sentences makes indexing in parallel algorithms\n",
        "complicated. To this avail, we sometimes want to pad all sentences to a fixed sentence\n",
        "length to ensure they can be stored in contiguous matrices easily.\n",
        "\n",
        "Lastly, as a common practice, we will want to create three new tokens ```<bos>``` and\n",
        "```<eos>``` for the start and the end of a given sequence and ```<unk>``` for unkown\n",
        "tokens in the application (test) layer or 0 padding during the training. These tokens\n",
        "must also be stored in the LUT.\n",
        "\n",
        "> TODO: Write the LUT computation. Ensure to incorporate the various additional tokens\n",
        "> in the process.\n",
        "\n",
        "> TODO: Write the Out-of-vocabulary word checking function\n",
        "\n",
        "> TODO: Write functions to pad sentences and to apply the LUT on the padded sentences.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_tokens_lut(train_dataset: EsposallesTextDataset) -> Dict[str, int]:\n",
        "    \"\"\"Create a LUT that maps each word to an index.\n",
        "\n",
        "    Construct a dictionary that takes a word as input and converts this word into an int\n",
        "    index. The indices must be unique and all words in the training dataset should have\n",
        "    one. Do not forget to incorporate extra tokens for beginning of sequence (<bos>),\n",
        "    end of sequence (<eos>) and unknown token (<unk>).\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    train_dataset : EsposallesTextDataset\n",
        "        Train data container that provides words and tokens one at a time.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Dict[str, int]\n",
        "        The LUT for words in the dataset.\n",
        "    \"\"\"\n",
        "    vocab = set()\n",
        "\n",
        "    for i in range(len(train_loader)):\n",
        "        words, _ = train_loader[i]\n",
        "        vocab.update(words)\n",
        "\n",
        "\n",
        "    lut = {\n",
        "        '<pad>': 0,\n",
        "        '<bos>': 1,    # start\n",
        "        '<eos>': 2,    # End\n",
        "        '<unk>': 3,    # Unknown\n",
        "    }\n",
        "\n",
        "    for idx, word in enumerate(sorted(vocab), start=4):\n",
        "        lut[word] = idx\n",
        "\n",
        "    return lut\n",
        "\n",
        "lut = create_tokens_lut(train_loader)\n"
      ],
      "metadata": {
        "id": "Zd_RUiP9sljM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fxkJj8tDe5WA"
      },
      "outputs": [],
      "source": [
        "def check_oov_words(lut: Dict[str, int], test_set: EsposallesTextDataset) -> List[str]:\n",
        "    \"\"\"Find all out-of-vocabulary words in the test partition.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    lut : Dict[str, int]\n",
        "        LUT you have calculated in the previous exercise with all of the words\n",
        "        present in the training partition.\n",
        "    test_set : EsposallesTextDataset\n",
        "        Test partition of the Esposalles dataset.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    List[str]\n",
        "        A list of words that are not found in the training partition.\n",
        "    \"\"\"\n",
        "    oov_words = set()\n",
        "\n",
        "    for i in range(len(test_set)):\n",
        "        words, _ = test_set[i]\n",
        "        for word in words:\n",
        "            if word not in lut:\n",
        "                oov_words.add(word)\n",
        "\n",
        "    return sorted(oov_words)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(check_oov_words(lut, test_loader)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6MjXKab8t3Hz",
        "outputId": "5139a620-2703-4239-b915-7c16f6181b68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Alaverni', 'Angli', 'Arevig', 'Argemir', 'Arisart', 'Assensio', 'Auger', 'Bachs', 'Begas', 'Berenguer', 'Blanquart', 'Bonastra', 'Box', 'Brasil', 'Broquets', 'Busquet', 'Buyra', 'Cabaner', 'Cabrer', 'Cabus', 'Campanya', 'Campderos', 'Campprecios', 'Cani', 'Carantela', 'Castellterçol', 'Castigaleu', 'Cebriana', 'Celles', 'Comi', 'Conflent', 'Constansa', 'Conteso', 'Corties', 'Crich', 'Darder', 'Deseny', 'Despi', 'Dimarts', 'Dimas', 'Garces', 'Gassull', 'Gatuellas', 'Ge', 'Glandina', 'Guardi#', 'Gusman', 'Honorat', 'Idrach', 'Islla', 'Juan#', 'Llobre', 'Llondra', 'Llorenci', 'Luciana', 'Macip', 'Majol', 'Manader', 'Mandri', 'Masseres', 'Melcior', 'Mercader', 'Miro', 'Monblanch', 'Monllor', 'Morros', 'Munmany', 'Muntells', 'Noguera', 'Novell', 'Pachs', 'Pallissa', 'Payas', 'Per', 'Peramon', 'Perris', 'Plans', 'Planta', 'Poses', 'Quart', 'Ratx', 'Ribagossa', 'Ritoreta', 'Rius', 'Rosa', 'Rotxe', 'Sengermes', 'Sitjar', 'Sobrevila', 'Spa', 'Sto', 'Tamuyell', 'Tarafa', 'Tatare', 'Terre', 'Testa', 'Theodora', 'Thome', 'Tibau', 'Valta', 'Victo', 'Vilademaser', 'Villaro', 'aguller', 'archebisbat', 'ayguardenter', 'basso', 'caxaler', 'clavetayre', 'comptat', 'deBarca', 'fabrega', 'fabres', 'faja', 'faliu', 'faneca', 'fargayre', 'febres', 'felis', 'fontanilles', 'francesa', 'galeras', 'gat', 'habitants', 'hor', 'imaginayre', 'jonqueres', 'more', 'moreno', 'mso', 'nyella', 'ortiz', 'pas', 'pinya', 'pobla', 'raguera', 'rianna', 'scrivent', 'tisser', 'tola', 'vivints']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oj0cq0SGUsgF"
      },
      "outputs": [],
      "source": [
        "MAX_SEQUENCE_LENGTH = 50\n",
        "\n",
        "def pad_sentence(sent: List[str], max_sent_len: int) -> List[str]:\n",
        "    \"\"\"Insert <bos>, <eos> in the sentence and add <pad> until max length.\n",
        "\n",
        "    If ``sent`` is lengthier than ``max_sent_len``, truncate the sentence and add the\n",
        "    final <eos>.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    sent : List[str]\n",
        "        An arbitrary length list of words representing a sentence.\n",
        "    max_sent_len : int\n",
        "        The desired max padding length.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    List[str]\n",
        "        The sentence with additional tokens and fixed width.\n",
        "    \"\"\"\n",
        "    padded = ['<bos>'] + sent[:max_sent_len - 2] + ['<eos>']\n",
        "    pad_len = max_sent_len - len(padded)\n",
        "    padded += ['<pad>'] * pad_len\n",
        "    return padded\n",
        "\n",
        "def apply_lut(lut: Dict[str, int], sent: List[str]) -> List[int]:\n",
        "    \"\"\"Convert words to indices using the LUT.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    lut : Dict[str, int]\n",
        "        LUT you have calculated in the previous exercise with all of the words\n",
        "        present in the training partition.\n",
        "    sent : List[str]\n",
        "        An arbitrary length list of words representing a padded sentence.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    List[int]\n",
        "        Same sentence as the input after applying the LUT.\n",
        "    \"\"\"\n",
        "    return [lut.get(word, lut.get('<unk>', 0)) for word in sent]\n",
        "\n",
        "# Since this exercise is for illustratory purposes, we will not care much about the\n",
        "# tags for now. If you wanted to do this for a real application, the tags would need\n",
        "# their own lut as well and the same padding would need to be applied on the source and\n",
        "# target sequences.\n",
        "tokenised_train = []\n",
        "for x, _ in train_loader:\n",
        "    # You could incorporate processing at this stage as well if you want\n",
        "    # x = process(x)\n",
        "    sent = pad_sentence(x, MAX_SEQUENCE_LENGTH)\n",
        "    sent = apply_lut(lut, sent)\n",
        "\n",
        "    tokenised_train.append(sent)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKuJPkJOanmB"
      },
      "source": [
        "## NER - Baseline Approach\n",
        "\n",
        "Let's actually start implementing sequence labelling algorithms. The first approach we\n",
        "will try is based on computing the probability of each tag for each word in our training\n",
        "corpus. With this simple approach we can obtain a baseline accuracy score.\n",
        "\n",
        "Since this is a very simple algorithm and we have very little data, we can work directly\n",
        "on strings to spare us a few headaches.\n",
        "\n",
        "> TODO: Write the ```compute_tag_prob``` function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYA9D-twbego"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "from typing import Dict\n",
        "\n",
        "def compute_tag_prob(train_loader: EsposallesTextDataset) -> Dict[str, Dict[str, float]]:\n",
        "    \"\"\"Compute the probability of each tag conditioned on the observed word.\n",
        "\n",
        "    The dictionary should look like:\n",
        "\n",
        "    >>> output = {\n",
        "    >>>     \"word\": {\n",
        "    >>>         \"other\": 0.1,\n",
        "    >>>         \"name\": 0.8,\n",
        "    >>>         \"surname\": 0.8,\n",
        "    >>>     },\n",
        "    >>> }\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    train_loader : EsposallesTextDataset\n",
        "        Train data container that provides words and tokens one at a time. It returns the\n",
        "        list of words and tags of each sentence:\n",
        "\n",
        "        >>> x, y = train_dataset[index]\n",
        "        x = ['Dilluns', 'hyacinto', ...]\n",
        "        y = ['other', 'name', ...]\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Dict[str, Dict[str, float]]\n",
        "        A dictionary whose keys are the words in the training corpus and whose values\n",
        "        are the probabilities of each tag inserted in a dictionary.\n",
        "    \"\"\"\n",
        "    # Initialize a dictionary to store counts of tags for each word\n",
        "    word_tag_counts = defaultdict(lambda: defaultdict(int))\n",
        "    tag_counts = defaultdict(int)\n",
        "\n",
        "    # Iterate over all sentences in the training dataset\n",
        "    for i in range(len(train_loader)):\n",
        "        x, y = train_loader[i]\n",
        "        for word, tag in zip(x, y):\n",
        "            word_tag_counts[word][tag] += 1\n",
        "            tag_counts[tag] += 1\n",
        "\n",
        "    # Convert counts to probabilities\n",
        "    word_tag_prob = {}\n",
        "    for word in word_tag_counts:\n",
        "        total_occurrences = sum(word_tag_counts[word].values())\n",
        "        word_tag_prob[word] = {\n",
        "            tag: count / total_occurrences\n",
        "            for tag, count in word_tag_counts[word].items()\n",
        "        }\n",
        "\n",
        "    return word_tag_prob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uFQe-5VykF9Q"
      },
      "outputs": [],
      "source": [
        "tag_probs = compute_tag_prob(train_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OozkEhtlQow-"
      },
      "source": [
        "At this point, as an example, your emissions dictionary should yield the following probabilities:\n",
        "\n",
        "$P(location |$ ```Prats``` $) = 18\\%$\n",
        "\n",
        "$P(surname |$ ```Prats``` $) = 72\\%$\n",
        "\n",
        "$P(other |$ ```Prats``` $) = 9\\%$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEFUzlRpQmTa",
        "outputId": "6044a7c1-1d51-42e6-ebe7-dc96328c5aaf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'location': 0.18181818181818182,\n",
              " 'surname': 0.7272727272727273,\n",
              " 'other': 0.09090909090909091}"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "tag_probs[\"Prats\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1JaHhJvcwK8"
      },
      "source": [
        "This method is, of course, quite limited by the fact that **it cannot model context**.\n",
        "It will output the most likely class for each word. However, you will find that this\n",
        "method works quite well in spite of its simplicity. Note that you will have to do a few\n",
        "assumptions for edge cases such as finding an out-of-vocabulary word.\n",
        "\n",
        "You have to analyse the results of this algorithm. You must implement a confusion matrix\n",
        "generator from the test set to aid you in this endeavour. Then, you can answer the\n",
        "following questions.\n",
        "\n",
        "* What do all of the mistakes have in common?\n",
        "* What kinds of words are the least performers?\n",
        "* What's your solution for out-of-vocabulary words? Can you provide a prediction for those?\n",
        "* What words are usually the best performers?\n",
        "\n",
        "CLUE: You should be getting around 88% precision if you do everything correctly.\n",
        "\n",
        "> TODO: Write the ```predict_test_set```, ```find_common_errors``` and ```compute_token_precision``` functions.\n",
        "\n",
        "> TODO: Analyse the results according to the previously stated questions."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Code to find the most frequent tag in the train set -> used to handle OOW\n",
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "def find_most_frequent_tag(train_set):\n",
        "    tag_count = defaultdict(int)  # Initialize a dictionary to count tag occurrences\n",
        "\n",
        "    # Iterate through the training set and count the tags\n",
        "    for i in range(len(train_set)):\n",
        "      x, y = train_set[i]\n",
        "\n",
        "    for tag in y:\n",
        "            tag_count[tag] += 1\n",
        "\n",
        "    # Find the tag with the highest count\n",
        "    most_frequent_tag = max(tag_count, key=tag_count.get)\n",
        "\n",
        "    return most_frequent_tag\n",
        "\n",
        "print(\"Most frequent tag:\", find_most_frequent_tag(train_loader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEyl7GaXqebx",
        "outputId": "7d391a7c-e32d-41fc-8ecd-e174707e62e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most frequent tag: other\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lDQeZ1_Zcbqx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac198d9d-d1e3-413a-82b2-5d75b047ee79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most common errors: {'location': 133, 'surname': 128, 'name': 27, 'other': 12, 'occupation': 39, 'state': 6}\n",
            "Precision: 0.8889604119729643\n"
          ]
        }
      ],
      "source": [
        "def predict_test_set(\n",
        "    tag_probs: Dict[str, Dict[str, float]],\n",
        "    test_set: EsposallesTextDataset,\n",
        ") -> List[List[str]]:\n",
        "    \"\"\"Implement the MLE algorithm for sequence tagging using the training tag probs.\n",
        "\n",
        "    Remember to consider cases such as OOV words.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    tag_probs : Dict[str, Dict[str, float]]\n",
        "        Dictionary of probabilities of each word to be of a certain tag.\n",
        "    test_set : EsposallesTextDataset\n",
        "        Test data container that provides words and tokens one at a time. It returns the\n",
        "        list of words and tags of each sentence:\n",
        "\n",
        "        >>> x, y = train_dataset[index]\n",
        "        x = ['Dilluns', 'hyacinto', ...]\n",
        "        y = ['other', 'name', ...]\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    List[List[str]]\n",
        "        A list of sentence-level predictions, which are in turn modeled as a list of\n",
        "        tags for each word in the sentence.\n",
        "    \"\"\"\n",
        "    test_predictions = []\n",
        "\n",
        "    # Iterate through the test set\n",
        "    for i in range(len(test_set)):\n",
        "      x, y = test_set[i]\n",
        "      predictions = []\n",
        "\n",
        "      for word in x:\n",
        "\n",
        "        if word in tag_probs.keys():\n",
        "          #find tag with highest prob\n",
        "          probabilities = tag_probs[word]\n",
        "          predicted_tag = max(probabilities, key=probabilities.get)\n",
        "\n",
        "        else:\n",
        "          predicted_tag = \"other\"\n",
        "\n",
        "        predictions.append(predicted_tag)\n",
        "\n",
        "      test_predictions.append(predictions)\n",
        "\n",
        "    return test_predictions\n",
        "\n",
        "def find_common_errors(\n",
        "    test_set: EsposallesTextDataset,\n",
        "    test_predictions: List[str],\n",
        ") -> Any:\n",
        "    \"\"\"Count how many times does some kind of error happen.\n",
        "\n",
        "    You can copy this function signature as many times as you want to create functions\n",
        "    that evaluate specific errors in the output.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Any\n",
        "        RETURN WHAT YOU WANT THAT YOU CAN USE TO EVALUATE THE MODEL.\n",
        "        Some suggestions:\n",
        "        - Dict[str, Dict[str, int]] -> Counts of every time a tag is confused by another\n",
        "        - Dict[str, int] -> Counts of which word is wrong\n",
        "        - Dict[str, int] -> Counts of which tag is wrong\n",
        "    \"\"\"\n",
        "    common_errors = defaultdict(int) # initialize with default vale of 0\n",
        "\n",
        "    # Iterate through the test set\n",
        "    for i in range(len(test_set)):\n",
        "      x_true, y_true = test_set[i]\n",
        "      y_pred = test_predictions[i]\n",
        "\n",
        "      for real_tag, predicted_tag in zip(y_true, y_pred):\n",
        "\n",
        "        # compare the predicted tag with the real one\n",
        "        if predicted_tag != real_tag:\n",
        "          # if incorreclty predicted increase dictionary count\n",
        "          common_errors[real_tag] += 1\n",
        "\n",
        "    # return a dictionary with the counts of which tag is wrong\n",
        "    return dict(common_errors)\n",
        "\n",
        "def compute_token_precision(\n",
        "    test_set: EsposallesTextDataset,\n",
        "    test_predictions: List[str],\n",
        ") -> float:\n",
        "    \"\"\"Compute how many times the prediction of the model is the same as the GT.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    test_set : EsposallesTextDataset\n",
        "        Test data container that provides words and tokens one at a time. It returns the\n",
        "        list of words and tags of each sentence:\n",
        "\n",
        "        >>> x, y = train_dataset[index]\n",
        "        x = ['Dilluns', 'hyacinto', ...]\n",
        "        y = ['other', 'name', ...]\n",
        "    test_predictions : List[str]\n",
        "        List of labels predicted by our MLE model.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    float\n",
        "        Precision computation for the full dataset.\n",
        "    \"\"\"\n",
        "    # initialize counts to 0\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "\n",
        "    # Iterate through the test set\n",
        "    for i in range(len(test_set)):\n",
        "      x_true, y_true = test_set[i]\n",
        "      y_pred = test_predictions[i]\n",
        "\n",
        "      for real_tag, predicted_tag in zip(y_true, y_pred):\n",
        "        total_predictions += 1\n",
        "\n",
        "        # compare the predicted tag with the real one\n",
        "        if predicted_tag == real_tag:\n",
        "          correct_predictions += 1\n",
        "\n",
        "    precision = correct_predictions / total_predictions\n",
        "\n",
        "    return precision\n",
        "\n",
        "test_predictions = predict_test_set(tag_probs, test_loader)\n",
        "err1 = find_common_errors(test_loader, test_predictions)\n",
        "print(\"Most common errors:\", err1)\n",
        "precision = compute_token_precision(test_loader, test_predictions)\n",
        "print(\"Precision:\", precision)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After finishing implementing the requested functions we obtained a **precision of 88%**, and concluded that the most commmonly missclassified tag was `location`. However, to further investigate the algorithm we will implement a function to create a **confusion matrix** from the test set and answer the requested questions."
      ],
      "metadata": {
        "id": "IxPxeum9qnCz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def generate_confusion_matrix(test_set, test_predictions, all_tags):\n",
        "\n",
        "    cm = defaultdict(lambda: defaultdict(int))\n",
        "\n",
        "    for i in range(len(test_set)):\n",
        "      x_true, y_true = test_set[i]\n",
        "      y_pred = test_predictions[i]\n",
        "\n",
        "      for y_true, y_pred in zip(y_true, y_pred):\n",
        "        cm[y_true][y_pred] +=1\n",
        "\n",
        "    # Convert to DataFrame for readability\n",
        "    cm_df = pd.DataFrame.from_dict(cm, orient='index').fillna(0).astype(int)\n",
        "    # Ensure all tags are included (even if zero)\n",
        "    cm_df = cm_df.reindex(index=all_tags, columns=all_tags, fill_value=0)\n",
        "\n",
        "    return cm_df\n",
        "\n",
        "\n",
        "all_tags = [\"location\", \"name\", \"occupation\", \"other\", \"state\", \"surname\"]\n",
        "cm = generate_confusion_matrix(test_loader, test_predictions, all_tags)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-PvcYkMqnoz",
        "outputId": "4025b8a8-c45f-44c7-af87-3e87f2416cc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "            location  name  occupation  other  state  surname\n",
            "location         329    11           1    111      0       10\n",
            "name               5   467           1     15      0        6\n",
            "occupation         1     0         255     37      0        1\n",
            "other              3     4           1   1481      2        2\n",
            "state              0     0           0      6    107        0\n",
            "surname           13    13           2    100      0      123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. What do all of the mistakes have in common?** <br>\n",
        "\n",
        "By looking at the off-diagonals of the confusion matrix, we see that many tags (e.g., surname, location, name, occupation) are often confused with `other`. This makes sense, since our approach to classify out-of-vocabulary words consisted on using the most frequent tag (`other`) for every unknown word. Therefore, in all categories (tags) we have missclassifications with the tag `other`. <br>\n",
        "\n",
        "Additionally, we see frequent confusion between name and surname. This is due to the fact that our classification relies solely on prior probabilities rather than contextual information. Since some names and surnames can overlap or be used interchangeably, distinguishing between them requires understanding the surrounding words in the sentence, something our current approach does not account for.\n",
        "\n"
      ],
      "metadata": {
        "id": "Lle6o4vJqpvD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. What kinds of words are the least performers?** <br>\n",
        "Looking at the confusion matrix, we can determine that the `state` and `surname` categories seem to be the least performers:\n",
        "\n",
        "> `State` has few correct predictions (107 on the diagonal), and it's frequently misclassified as `other` or other categories.\n",
        "\n",
        "> `Surname` also has significant misclassifications (13 to name, 13 to surname, 100 to other).\n",
        "\n",
        "The fact that `state` and `surname` are the least well-performing categories, can be due to the fact that:\n",
        "\n",
        "The dataset includes a wide variety of personal and historical names, where state tags are less frequent and more difficult to identify. In historical texts or records, such as the one we are using, there can be different ways of referring to locations or statuses, which can lead to confusion between state and location or other tags.\n",
        "\n",
        "Many surnames are commonly used as first names. For example, in cases where a person’s full name includes a surname that could also be a common first name, the model struggles to differentiate between the two categories.\n",
        "\n",
        "It is also important to note that `location` also shows some confusion, this is because some locations can be mislabelled as names or surnames, for instance \"Bara\" or \"Vila\" can be both a surname or a location, the only way we have of differentiating it is using the context."
      ],
      "metadata": {
        "id": "ZbHj4Xykqr_D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. What's your solution for out-of-vocabulary words? Can you provide a  prediction for those?** <br>\n",
        "To deal with out-of-vocabulary words, we assigned them the most common tag in the data, therefore being able to provide a prediction. However, this method is not very accurate since many words end up being misclassified as `other`. Despite this, we were still able to obtain a proper accuracy. A better approach could be using word embeddings, which help understand word meanings based on their context, to predict the correct tags more accurately."
      ],
      "metadata": {
        "id": "4ODlAj2jqvfl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. What words are usually the best performers?** <br>\n",
        "The best-performing words in the confusion matrix are those with the highest correct classifications (diagonal values) and the lowest\n",
        "misclassifications (off-diagonal values). <br>\n",
        "\n",
        "The `other` category performs the best, with 1481 correct classifications and very few misclassifications. This is explained by the solution that we provided to OOV words, for example, words like \"fill\" that are not part of the common tags in the dataset, are correctly labeled as `other`, helping improve the performance in this category.\n",
        "\n",
        "Similarly, `name` (467 correct) and `occupation` (255 correct) also perform well. For instance, in our dataset, names like \"Joan\" and \"Pere\" are frequently classified correctly as `name`. Likewise, words like \"pastisser\" are correctly identified as occupation. These categories perform well because they follow clear patterns in the dataset, with names and occupations being easily recognizable and distinct from other types of words.\n"
      ],
      "metadata": {
        "id": "SbwLcS6eqyGM"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yd67-fWgl3LR"
      },
      "source": [
        "## HMM Approach\n",
        "\n",
        "As demonstrated in the previous experiment, using just the priors have not enough\n",
        "expresivity for managing both out of vocabulary words and polysemic words. Here we will\n",
        "use the ```python-crfsuite``` module to build a Hidden Markov Model and improve the\n",
        "predictions on ```test_set```.\n",
        "\n",
        "Check <a href = 'https://python-crfsuite.readthedocs.io/en/latest/'>here</a> the  ```python-crfsuite``` documentation.\n",
        "\n",
        "First, we will set up the parameters for our HMM model.\n",
        "\n",
        "*The HMM will be implemented using CRFs, because at the end of the day a HMM is\n",
        "more or less equivalent to a CRF that uses only the current emitted word and the\n",
        "previous tag as features.*\n",
        "\n",
        "> TODO: Train the HMM and compare it to the baseline approach. Where is it better?\n",
        "\n",
        "> TODO: Check which tag transitions are most common. Rationalise why this is the case\n",
        "> and contextualise it with the type of input data you have. Do they make sense?\n",
        "\n",
        ">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1lHnkC3Wl3LR"
      },
      "outputs": [],
      "source": [
        "def get_word_to_hmm_features(sent: List[Tuple[str, str]], i: int) -> List[str]:\n",
        "    \"\"\"This function computes CRF features to generate a HMM from a word.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    sent : List[str]\n",
        "        Sentence to extract features from.\n",
        "    i : int\n",
        "        Index of the word whose features should be extracted.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    List[str]\n",
        "        A list of features for the i-th word.\n",
        "    \"\"\"\n",
        "    word, _ = sent[i]\n",
        "\n",
        "    # The features we care about are the current emitted word and whether this word is\n",
        "    # at the beginning or the end of a sentence.\n",
        "    features = [\n",
        "        \"bias\",\n",
        "        \"word.lower=\" + word.lower(),\n",
        "    ]\n",
        "    if i == 0:\n",
        "        features.append(\"bos\")\n",
        "\n",
        "    if i == len(sent) - 1:\n",
        "        features.append(\"eos\")\n",
        "\n",
        "    return features\n",
        "\n",
        "\n",
        "def get_sent_to_hmm_features(sent: List[Tuple[str, str]]) -> List[List[str]]:\n",
        "    \"\"\"Extract HMM-CRF features for a full sentence.\"\"\"\n",
        "    return [get_word_to_hmm_features(sent, i) for i in range(len(sent))]\n",
        "\n",
        "\n",
        "def sent2labels(sent: List[Tuple[str, str]]) -> List[str]:\n",
        "    \"\"\"Get labels from the sentence tuple format.\"\"\"\n",
        "    return [label for token, label in sent]\n",
        "\n",
        "\n",
        "def sent2tokens(sent: List[Tuple[str, str]]) -> List[str]:\n",
        "    \"\"\"Get words from the sentence tuple format.\"\"\"\n",
        "    return [token for token, label in sent]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "soe5AD6sl3LR"
      },
      "outputs": [],
      "source": [
        "# Transform the dataset to the (token, gt) tuple format\n",
        "train_sents = [\n",
        "    [(x, y) for x, y in zip(*train_loader[idx])] for idx in range(len(train_loader))\n",
        "]\n",
        "test_sents = [\n",
        "    [(x, y) for x, y in zip(*train_loader[idx])] for idx in range(len(test_loader))\n",
        "]\n",
        "\n",
        "X_train = [get_sent_to_hmm_features(s) for s in train_sents]\n",
        "y_train = [sent2labels(s) for s in train_sents]\n",
        "\n",
        "X_test = [get_sent_to_hmm_features(s) for s in test_sents]\n",
        "y_test = [sent2labels(s) for s in test_sents]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H2Vw1vz5l3LS"
      },
      "outputs": [],
      "source": [
        "trainer = crfs.Trainer(verbose=False)  # Instance a CRF trainer\n",
        "\n",
        "for xseq, yseq in zip(X_train, y_train):\n",
        "    trainer.append(xseq, yseq)  # Stack the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKK8wZDnl3LS"
      },
      "source": [
        "You can modify these hyperparameters if you wish. Check the documentation to see if\n",
        "there are some additions you can make here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "snOeN8Wql3LS"
      },
      "outputs": [],
      "source": [
        "trainer.set_params(\n",
        "    {\n",
        "        \"c1\": 1.0,  # coefficient for L1 penalty\n",
        "        \"c2\": 1e-3,  # coefficient for L2 penalty\n",
        "        \"max_iterations\": 50,  # Max Number of iterations for the iterative algorithm\n",
        "        # include transitions that are possible, but not observed (smoothing)\n",
        "        \"feature.possible_transitions\": True,\n",
        "        \"num_memories\": 6,  # Number of previous updates kept for convergence detection\n",
        "        \"epsilon\": 1e-5,  # Tolerance for stopping criteria\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We added `num_memories` so that the optimizer retains some memory of the previous 6 updates, if increased too much it can lead to a smoother convergence but to a slower computation, which is why we set it to *6* in order to find a trade-off between the smoother convergence and a reasonable computation time.\n",
        "\n",
        "\n",
        "We also added `epsilon` which controls when the optimization algorithm should stop training. Specifically, it defines the minimum change in the objective function between iterations before stopping. If the model function is lower than epsilon, the algorithm assumes the model has converged and stops early."
      ],
      "metadata": {
        "id": "GIT1BkGkst9P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TGtRyLeOl3LS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "473d557d-13e5-4d13-abd5-8eca9eb4b667"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 672 ms, sys: 4.49 ms, total: 677 ms\n",
            "Wall time: 729 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "trainer.train('npl_ner_hmm.crfsuite') # Train the model and save it locally."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZIs0jFnl3LS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f69d08fe-8489-4228-c461-31fd14b75253"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<contextlib.closing at 0x7bf9ea18fad0>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "tagger = crfs.Tagger()\n",
        "tagger.open(\"npl_ner_hmm.crfsuite\")  # Load the inference API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r0pqIH2Ql3LS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cbf81c9-ca52-49c2-d3e3-11ba8bba5d51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dilluns a 5 rebere de Hyacinto Boneu hortola de Bara fill de Juan Boneu parayre defunct y de Maria ab Anna donsella filla de t Cases pages de Bara defunct y de Peyrona\n",
            "\n",
            "Predicted: other other other other other name surname occupation other location other other name surname occupation other other other name other name state other other name surname occupation other location other other other name\n",
            "Correct:   other other other other other name surname occupation other location other other name surname occupation other other other name other name state other other name surname occupation other location other other other name\n"
          ]
        }
      ],
      "source": [
        "example_sent = test_sents[0]\n",
        "print(\" \".join(sent2tokens(example_sent)), end=\"\\n\\n\")\n",
        "\n",
        "print(\"Predicted:\", \" \".join(tagger.tag(get_sent_to_hmm_features(example_sent))))\n",
        "print(\"Correct:  \", \" \".join(sent2labels(example_sent)))  # Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nw7CLEtYl3LS"
      },
      "source": [
        "In the following code, you have a way of checking which of the most common state\n",
        "transitions are present in the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sef5GxZ_l3LS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "375561cd-434f-467c-da38-ee4e1896d650"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top likely transitions:\n",
            "surname -> occupation 5.019786\n",
            "location -> location 4.249178\n",
            "occupation -> occupation 4.194908\n",
            "name   -> surname 3.918272\n",
            "surname -> surname 3.294527\n",
            "other  -> name    2.642988\n",
            "name   -> name    2.280106\n",
            "other  -> location 1.814986\n",
            "occupation -> other   1.799188\n",
            "state  -> state   1.515564\n",
            "name   -> state   1.182575\n",
            "other  -> other   1.181984\n",
            "state  -> other   0.735261\n",
            "occupation -> state   0.467426\n",
            "location -> other   0.403282\n",
            "\n",
            "Top unlikely transitions:\n",
            "state  -> occupation 0.214062\n",
            "surname -> state   0.070542\n",
            "location -> occupation -0.072833\n",
            "name   -> other   -0.506374\n",
            "occupation -> name    -0.617364\n",
            "other  -> surname -0.626089\n",
            "occupation -> location -0.735001\n",
            "surname -> name    -0.998662\n",
            "other  -> occupation -1.030786\n",
            "other  -> state   -1.296538\n",
            "name   -> occupation -1.650451\n",
            "occupation -> surname -2.111763\n",
            "name   -> location -2.166658\n",
            "location -> surname -2.771394\n",
            "location -> name    -3.351583\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "info = tagger.info()\n",
        "\n",
        "\n",
        "def print_transitions(trans_features):\n",
        "    for (label_from, label_to), weight in trans_features:\n",
        "        print(\"%-6s -> %-7s %0.6f\" % (label_from, label_to, weight))\n",
        "\n",
        "\n",
        "print(\"Top likely transitions:\")\n",
        "print_transitions(Counter(info.transitions).most_common(15))\n",
        "\n",
        "print(\"\\nTop unlikely transitions:\")\n",
        "print_transitions(Counter(info.transitions).most_common()[-15:])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Study the kinds of transitions the model has learnt. Do they make sense?**\n",
        "\n",
        "The most likely transition is the one from `surname` to `occupation` (5.01). This makes sense given the structured nature (as mentioned above) of historical marriage records. Which typically follow a predictable format, often listing a person's full name first (name -> surname), followed by their occupation (surname -> occupation).\n",
        "\n",
        "It also has a high probability transition from `location` to `location`(4.25) and `occupation` to `occupation` (4.19). This means that if a word is identified as a location or occupation, the HMM is less likely to switch the label mid-sentence. In contrast, CRF relies more on individual word features, so it sometimes misclassifies long sequences.\n",
        "\n",
        "> For instance, in the sentence \"... ciutat de Barcelona.\" we would want to label \"ciutat de Barcelona\", all together, as a location (location -> location).\n",
        "\n",
        "> Another example would be in the sentence: \"Pere Roca, mestre de cases de Barcelona.\", where \"mestre de cases\" should be labelled as a single occupation (occupation -> occupation), rather than tagging \"mestre\" as an occupation and \"de\", \"cases\" as something else.\n",
        "\n",
        "The HMM also has a strong probability transition from `name` to `surname` (3.9) which means that it has learned that surnames often follow names. Which is logical due to the dataset that we are using, where names are listed before surnames.\n",
        "\n",
        "Other transitions that are also pretty common are the ones from `surname`to `surname`, `name`to `name`, or `other`to `name`.\n",
        "\n",
        "> For instance, \"Joan Ferrer i Vila\" contains two consecutive surnames, reinforcing the surname -> surname transition.\n",
        "\n",
        "> First names frequently appear in succession when listing family members, leading to the name -> name transition.\n",
        "\n",
        "> Lastly, the other -> name transition is expected since generic words like \"fill de\" or \"amb\" often precede a person’s name."
      ],
      "metadata": {
        "id": "sxsIrgBO5Hro"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y2I7lCAJl3LS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09d644e8-6aba-4645-dd14-3516e6b01ffa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top positive:\n",
            "10.471530 state  word.lower=viudo\n",
            "9.201264 state  word.lower=donsella\n",
            "9.171407 other  word.lower=ab\n",
            "9.073835 other  word.lower=fill\n",
            "9.043569 other  word.lower=defuncts\n",
            "8.975021 other  word.lower=#\n",
            "8.538504 state  word.lower=viuda\n",
            "8.204700 other  word.lower=defunct\n",
            "7.974212 other  word.lower=y\n",
            "7.971931 other  word.lower=defuncta\n",
            "7.816721 location word.lower=frances\n",
            "7.655355 state  word.lower=dosella\n",
            "7.522998 other  word.lower=rebere\n",
            "7.259508 other  word.lower=habitant\n",
            "7.223392 location word.lower=bara\n",
            "7.056602 other  word.lower=a\n",
            "6.963770 other  word.lower=de\n",
            "6.655697 other  word.lower=filla\n",
            "6.586878 other  word.lower=habitat\n",
            "6.535491 occupation word.lower=llana\n",
            "\n",
            "Top negative:\n",
            "0.009387 occupation word.lower=pastisser\n",
            "0.006814 surname word.lower=pere\n",
            "-0.000147 name   word.lower=sr\n",
            "-0.000667 location word.lower=dels\n",
            "-0.015598 location word.lower=menat\n",
            "-0.061897 surname word.lower=vila\n",
            "-0.086558 surname word.lower=del\n",
            "-0.118397 surname word.lower=toni\n",
            "-0.285311 occupation bias\n",
            "-0.398388 location word.lower=habitant\n",
            "-0.422007 surname eos\n",
            "-0.499756 location word.lower=pages\n",
            "-0.504381 surname word.lower=texidor\n",
            "-0.558585 surname word.lower=y\n",
            "-0.694049 surname word.lower=#\n",
            "-0.757626 state  bias\n",
            "-1.027974 occupation word.lower=del\n",
            "-1.104222 location word.lower=en\n",
            "-1.170696 surname word.lower=serrat\n",
            "-1.568957 location word.lower=domiciliat\n"
          ]
        }
      ],
      "source": [
        "def print_state_features(state_features):\n",
        "    for (attr, label), weight in state_features:\n",
        "        print(\"%0.6f %-6s %s\" % (weight, label, attr))\n",
        "\n",
        "\n",
        "print(\"Top positive:\")\n",
        "print_state_features(Counter(info.state_features).most_common(20))\n",
        "\n",
        "print(\"\\nTop negative:\")\n",
        "print_state_features(Counter(info.state_features).most_common()[-20:])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Where does the HMM perform better than the baseline approach?** <br>\n",
        "The HMM model outperforms the baseline approach when predicting unknown words in our dataset, which consists of structured and predictable texts.\n",
        "\n",
        "Since the HMM approach relies on **transition probabilities** rather than specific word features, it can generalize better to **unseen words**, making it more robust in historical records, such as the one we are using (historical record of marriages), where spelling variations and rare terms are common.\n",
        "\n",
        "Additionally, our dataset follows a **fixed structure**, where names, surnames, occupations, and locations often appear in a structured sequence. Therefore, allowing the HMM to strengthen sequence patterns for more accurate predictions.\n",
        "\n",
        "> *Each marriage license contains information about the husband’s occupation, husband’s and wife’s former marital status, socioeconomic position signaled by the fee imposed on them,  and in some cases, fathers’ occupations,  place of residence or geographical origin.* - *extracted from: http://dag.cvc.uab.es/the-esposalles-database/*\n",
        "\n",
        "In contrast, the NER model, which heavily depends on word features, struggles with rare or unseen words and lacks the same ability to enforce structured labeling."
      ],
      "metadata": {
        "id": "H2whlDh4v4_y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. What words does it struggle with?** <br>\n",
        "The HMM struggles with words that do not follow the predicted structure or transitions learned. As well as unknown words or words that do not appear that frequently in the dataset, such as \"menat\" or \"pastisser\".\n",
        "\n",
        "Additionally, it can also struggle with alternative spelling of names or locations. For instance, \"Esposalles\" might sometimes be written as \"Esposallès\" or \"Esposalles\", which could cause the model to misclassify it as a location.\n",
        "\n",
        "Lastly, common words like \"de\", \"i\", or \"amb\" that appear frequently in these records are difficult for the HMM to classify, as they don’t carry significant meaning or have clear transitions to another tag."
      ],
      "metadata": {
        "id": "pSybt1Kwv_iG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. How differently does the model perform w.r.t Out-of-Vocabulary words?**"
      ],
      "metadata": {
        "id": "L7P4azWmwEEf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The HMM model handles Out-of-Vocabulary words better than our baseline approach because it focuses on transitions between labels rather than relying on specific word features. When the HMM encounters a new word, it can use the surrounding context to make a good guess based on patterns learned during training. For example, if it comes across a new name or occupation, it can apply its knowledge of past transitions (like surname -> occupation) to predict the label accurately.\n",
        "\n",
        "In contrast, with our first approach, any unknown word had to be classified as `other`, which limited the model's ability to make accurate predictions and led to a lot of mislabeling, with many words incorrectly tagged as `other`.\n",
        "\n",
        "The HMM is particularily useful for out-of-vocabulary words in this dataset, since as mentioned above, words appear in a more or less structured sequence. Therefore, the transitions learned are really useful to predict them."
      ],
      "metadata": {
        "id": "D328S6xV-UNp"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPkXV9zGl3LS"
      },
      "source": [
        "## Optional: Use arbitrary CRF Features\n",
        "\n",
        "You can try to extract finer-grained features if you want using a CRF model. If you do\n",
        "so, provide the same analysis of results as with the HMM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_nEkmHldl3LS"
      },
      "outputs": [],
      "source": [
        "def get_word_to_crf_features(sent: List[Tuple[str, str]], i: int) -> List[str]:\n",
        "    \"\"\"This function computes CRF features from a word.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    sent : List[str]\n",
        "        Sentence to extract features from.\n",
        "    i : int\n",
        "        Index of the word whose features should be extracted.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    List[str]\n",
        "        A list of features for the i-th word.\n",
        "    \"\"\"\n",
        "    word, _ = sent[i]\n",
        "\n",
        "    features = [\n",
        "        \"bias\",\n",
        "        \"word.lower=\" + word.lower(),\n",
        "        \"word[-2:]=\" + word[-2:],\n",
        "        \"word.istitle=%s\" % word.istitle(),\n",
        "        \"word.isdigit=%s\" % word.isdigit(),\n",
        "    ]\n",
        "\n",
        "    if i > 0:\n",
        "        prev_word = sent[i - 1][0]\n",
        "        features.extend([\n",
        "            \"-1:word.lower=\" + prev_word.lower(),\n",
        "            \"-1:word.istitle=%s\" % prev_word.istitle()\n",
        "        ])\n",
        "    else:\n",
        "        features.append(\"bos\")\n",
        "\n",
        "    if i < len(sent) - 1:\n",
        "        next_word = sent[i + 1][0]\n",
        "        features.extend([\n",
        "            \"+1:word.lower=\" + next_word.lower(),\n",
        "            \"+1:word.istitle=%s\" % next_word.istitle()\n",
        "        ])\n",
        "    else:\n",
        "        features.append(\"eos\")\n",
        "\n",
        "    return features\n",
        "\n",
        "\n",
        "def get_sent_to_crf_features(sent: List[Tuple[str, str]]) -> List[List[str]]:\n",
        "    \"\"\"Extract HMM-CRF features for a full sentence.\"\"\"\n",
        "    return [get_word_to_crf_features(sent, i) for i in range(len(sent))]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DMsfu86pl3LS"
      },
      "outputs": [],
      "source": [
        "crf_trainer = crfs.Trainer(verbose=False)  # Instance a CRF trainer\n",
        "\n",
        "for xseq, yseq in zip(X_train, y_train):\n",
        "    crf_trainer.append(xseq, yseq)  # Stack the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sF9vjvIIl3LS"
      },
      "outputs": [],
      "source": [
        "# Set CRF training parameters\n",
        "crf_trainer.set_params({\n",
        "        \"c1\": 1.0,  # coefficient for L1 penalty\n",
        "        \"c2\": 1e-3,  # coefficient for L2 penalty\n",
        "        \"max_iterations\": 50,  # Max Number of iterations for the iterative algorithm\n",
        "        # include transitions that are possible, but not observed (smoothing)\n",
        "        \"feature.possible_transitions\": True,\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "839O5P-ql3LS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c70e31e9-ea11-4cb8-ae18-a07a4042833d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 638 ms, sys: 4.79 ms, total: 642 ms\n",
            "Wall time: 696 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "trainer.train('npl_ner_crf.crfsuite') # Train the model and save it locally."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The two functions, `get_word_to_hmm_features` and `get_word_to_crf_features`, are designed to extract features from words in a sentence, but they differ in complexity and purpose. The HMM (Hidden Markov Model) version is much simpler: it only includes the lowercase version of the current word and flags if it's the beginning or end of a sentence. This minimalistic approach is quite fast and that’s reflected in the CPU and wall times: **672 ms user / 729 ms wall**.\n",
        "\n",
        "In contrast, the CRF (Conditional Random Field) version adds much more context. It not only uses the current word’s lowercase form but also checks if the word is capitalized, if it's numeric, and includes the last two letters of the word. It also looks at features from neighboring words (previous and next), which increases both its contextual richness and computational load. This richer feature set helps CRFs make more informed predictions but comes with a slight performance cost: **638 ms user / 696 ms wall**.\n",
        "\n",
        "Surprisingly, despite CRF doing more work, it’s *slightly* faster in both CPU and wall time here. However, in this case, **the HMM function is simpler and expected to be faster**, while **the CRF function, although a bit heavier, offers better performance in terms of learning potential due to more context-aware features**.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "Uys_4fIjj1QL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tagger = crfs.Tagger()\n",
        "tagger.open(\"npl_ner_crf.crfsuite\")\n",
        "\n",
        "y_pred = [tagger.tag(xseq) for xseq in X_test]\n",
        "\n",
        "from sklearn_crfsuite import metrics\n",
        "\n",
        "print(\"CRF Accuracy:\", metrics.flat_accuracy_score(y_test, y_pred))\n",
        "print(metrics.flat_classification_report(y_test, y_pred, digits=3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMxQcpgDfZLb",
        "outputId": "651c65ea-30d7-4431-bd1d-8b4d14ab10e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CRF Accuracy: 0.9732724902216427\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    location      0.952     0.952     0.952       416\n",
            "        name      0.982     0.982     0.982       487\n",
            "  occupation      0.929     0.973     0.950       296\n",
            "       other      0.988     0.981     0.984      1486\n",
            "       state      0.966     0.982     0.974       114\n",
            "     surname      0.966     0.944     0.955       269\n",
            "\n",
            "    accuracy                          0.973      3068\n",
            "   macro avg      0.964     0.969     0.966      3068\n",
            "weighted avg      0.974     0.973     0.973      3068\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "NLP",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}